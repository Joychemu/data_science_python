{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHAT IS NLTK?\n",
    "- It is a powerful python pacakge that provides a set of diverse natural lnaguage algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE BASICS OF NLP FOR TEXT\n",
    "1. Sentence Tokenization\n",
    "2. Word Tokenization\n",
    "3. Text Lemmatization and stemming\n",
    "4. Stop words\n",
    "5. Part of speech Tagging (POS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the nltk library\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What id Tokenization?\n",
    "* Tokenization is often the first step in text analytics.\n",
    "* It is a process of breaking down a texts into smaller chunks of words called tokens.\n",
    "* Token is a Single entity that is a building block s for sentence or paragraph.\n",
    "\n",
    "1. Sentence tokenization\n",
    "Break down a paragraph into sentences.\n",
    "\n",
    "2. Word Tokenization\n",
    "Break down a sentence into words, also called word segemntation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Mr. Smith, how are you doing today?',\n",
       " 'The weather is great, and city is awesome.The sky is pinkish-blue.',\n",
       " \"You shouldn't eat cardboard\"]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence Tokenization\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text_one=\"Hello Mr. Smith, how are you doing today? The weather is great, and city is awesome.The sky is pinkish-blue. You shouldn't eat cardboard\"\n",
    "\n",
    "# tokenized the text_one\n",
    "tokenized_paragraph = sent_tokenize(text_one)\n",
    "\n",
    "tokenized_paragraph\n",
    "\n",
    "# print(len(tokenized_paragraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Backgammon is one of the oldest known board games.\n",
      "2. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East.\n",
      "3. It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll\n",
      "of two dice.\n"
     ]
    }
   ],
   "source": [
    "text_two = \"\"\"Backgammon is one of the oldest known board games. \n",
    "Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. \n",
    "It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll\n",
    "of two dice.\n",
    "\"\"\"\n",
    "tokenized_paragraph_two = sent_tokenize(text_two)\n",
    "\n",
    "for x in tokenized_paragraph_two:\n",
    "    a= tokenized_paragraph_two.index(x) +1\n",
    "    print(f\"{a}.\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Mr. Smith , how are you doing today ? The weather is great , and city is awesome.The sky is pinkish-blue . You should n't eat cardboard "
     ]
    }
   ],
   "source": [
    "# Word Tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized_word = word_tokenize(text_one)\n",
    "\n",
    "#tokenized_word\n",
    "\n",
    "for x in tokenized_word:\n",
    "    print(x,\"\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
